{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Define Path and Load Data ---\n",
    "\n",
    "DATA_PATH = '../data/TMDB_all_movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at the specified path: {DATA_PATH}\")\n",
    "    print(\"Please make sure the dataset is in the 'data/' folder and the filename is correct.\")\n",
    "    # Assign df to None if loading fails, to prevent errors in subsequent cells.\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cleaning and pre-processing complete.\n",
      "DataFrame shape after initial cleaning: (644474, 12)\n"
     ]
    }
   ],
   "source": [
    "# This cell performs the initial data cleaning, type correction, and column selection.\n",
    "\n",
    "# --- 1. Select Relevant Columns & Make a Copy ---\n",
    "# We select only the columns needed for features and final output.\n",
    "columns_to_keep = [\n",
    "    'id', 'title', 'overview', 'genres', 'cast', 'director', \n",
    "    'vote_average', 'vote_count', 'release_date', 'poster_path', 'status'\n",
    "]\n",
    "df_clean = df[columns_to_keep].copy()\n",
    "\n",
    "\n",
    "# --- 2. Basic Filtering ---\n",
    "# We only want to recommend movies that have actually been released.\n",
    "df_clean = df_clean[df_clean['status'] == 'Released']\n",
    "\n",
    "# A movie without a title, overview, or genres cannot be used.\n",
    "df_clean.dropna(subset=['title', 'overview', 'genres'], inplace=True)\n",
    "\n",
    "\n",
    "# --- 3. Correct Data Types ---\n",
    "# Create a 'year' column for display and potential filtering\n",
    "df_clean['year'] = pd.to_datetime(df_clean['release_date'], errors='coerce').apply(\n",
    "    lambda x: str(x.year) if pd.notna(x) else None\n",
    ")\n",
    "\n",
    "# Ensure numeric columns are numeric, filling errors with 0\n",
    "df_clean['vote_count'] = pd.to_numeric(df_clean['vote_count'], errors='coerce').fillna(0)\n",
    "df_clean['vote_average'] = pd.to_numeric(df_clean['vote_average'], errors='coerce').fillna(0)\n",
    "\n",
    "# Drop any rows that might have become null during coercion\n",
    "df_clean.dropna(subset=['year', 'vote_count', 'vote_average'], inplace=True)\n",
    "\n",
    "\n",
    "# --- 4. Final Index Reset ---\n",
    "# This ensures a clean, contiguous index before we begin feature engineering.\n",
    "df_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "print(\"Initial cleaning and pre-processing complete.\")\n",
    "print(f\"DataFrame shape after initial cleaning: {df_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Parsing features: genres, cast, director ---\n",
      "Feature parsing complete.\n",
      "\n",
      "--- Creating narrative documents for semantic encoding ---\n",
      "Narrative documents created successfully.\n"
     ]
    }
   ],
   "source": [
    "# This cell defines parsing functions and creates our rich feature columns.\n",
    "\n",
    "# --- 1. Define Helper Functions ---\n",
    "def parse_comma_separated_list(text_data, top_n=None):\n",
    "    \"\"\"Parses a comma-separated string into a list of strings.\"\"\"\n",
    "    if not isinstance(text_data, str): return []\n",
    "    items = [item.strip() for item in text_data.split(',')]\n",
    "    return items[:top_n] if top_n else items\n",
    "\n",
    "def clean_names_in_list(name_list):\n",
    "    \"\"\"Cleans a list of names by making them lowercase and removing spaces.\"\"\"\n",
    "    if not isinstance(name_list, list): return []\n",
    "    # Ensure all items are strings before applying string methods\n",
    "    return [str(name).lower().replace(' ', '') for name in name_list]\n",
    "\n",
    "# --- 2. Apply Parsing to Create Feature Lists ---\n",
    "print(\"--- Parsing features: genres, cast, director ---\")\n",
    "df_clean['genres_list'] = df_clean['genres'].apply(parse_comma_separated_list)\n",
    "df_clean['cast_list'] = df_clean['cast'].apply(lambda x: clean_names_in_list(parse_comma_separated_list(x, top_n=3)))\n",
    "df_clean['director_list'] = df_clean['director'].apply(lambda x: clean_names_in_list(parse_comma_separated_list(x)))\n",
    "print(\"Feature parsing complete.\")\n",
    "\n",
    "# --- 3. Create the \"Narrative Document\" for BGE Model ---\n",
    "print(\"\\n--- Creating narrative documents for semantic encoding ---\")\n",
    "def create_narrative_document(row):\n",
    "    \"\"\"Creates a natural language paragraph combining key movie features.\"\"\"\n",
    "    directors = ' and '.join(row.get('director_list', []))\n",
    "    cast_list = row.get('cast_list', [])\n",
    "    \n",
    "    if len(cast_list) > 1:\n",
    "        cast_str = ', '.join(cast_list[:-1]) + ' and ' + cast_list[-1]\n",
    "    elif cast_list:\n",
    "        cast_str = cast_list[0]\n",
    "    else:\n",
    "        cast_str = \"\"\n",
    "\n",
    "    title_sentence = f\"The movie is titled {row.get('title', '')}.\"\n",
    "    genre_sentence = f\"It is a {' and '.join(row.get('genres_list', []))} film.\"\n",
    "    director_sentence = f\"This film was directed by {directors}.\" if directors else \"\"\n",
    "    cast_sentence = f\"It stars {cast_str}.\" if cast_str else \"\"\n",
    "    overview_sentence = f\"The plot is as follows: {row.get('overview', '')}\"\n",
    "    \n",
    "    # Combine all sentences into a single, coherent paragraph\n",
    "    narrative = ' '.join(filter(None, [title_sentence, genre_sentence, director_sentence, cast_sentence, overview_sentence]))\n",
    "    return narrative\n",
    "\n",
    "df_clean['narrative_text'] = df_clean.apply(create_narrative_document, axis=1)\n",
    "print(\"Narrative documents created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Calculating global metrics for Weighted Rating ---\n",
      "Global mean rating (C): 2.8528\n",
      "Global vote count threshold (m) at 95th percentile: 50.0\n",
      "\n",
      "Number of 'qualified' movies passing the threshold: 32314\n",
      "Weighted Rating (wr) calculated for all qualified movies.\n",
      "Final number of unique, high-quality movies for our engine: 30269\n",
      "\n",
      "Top 15 Movies based on the new Weighted Rating:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>wr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>28432.0</td>\n",
       "      <td>8.711</td>\n",
       "      <td>8.700716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>21550.0</td>\n",
       "      <td>8.686</td>\n",
       "      <td>8.672497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>13014.0</td>\n",
       "      <td>8.571</td>\n",
       "      <td>8.549115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>1993</td>\n",
       "      <td>16468.0</td>\n",
       "      <td>8.564</td>\n",
       "      <td>8.546712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Spirited Away</td>\n",
       "      <td>2001</td>\n",
       "      <td>17218.0</td>\n",
       "      <td>8.537</td>\n",
       "      <td>8.520541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>33960.0</td>\n",
       "      <td>8.520</td>\n",
       "      <td>8.511668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>1999</td>\n",
       "      <td>18150.0</td>\n",
       "      <td>8.505</td>\n",
       "      <td>8.489472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>1994</td>\n",
       "      <td>28767.0</td>\n",
       "      <td>8.488</td>\n",
       "      <td>8.478222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21756</th>\n",
       "      <td>Your Name.</td>\n",
       "      <td>2016</td>\n",
       "      <td>11814.0</td>\n",
       "      <td>8.500</td>\n",
       "      <td>8.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>2003</td>\n",
       "      <td>25160.0</td>\n",
       "      <td>8.486</td>\n",
       "      <td>8.474827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>9195.0</td>\n",
       "      <td>8.500</td>\n",
       "      <td>8.469458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994</td>\n",
       "      <td>28297.0</td>\n",
       "      <td>8.468</td>\n",
       "      <td>8.458096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18073</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>2014</td>\n",
       "      <td>37303.0</td>\n",
       "      <td>8.455</td>\n",
       "      <td>8.447501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>Dilwale Dulhania Le Jayenge</td>\n",
       "      <td>1995</td>\n",
       "      <td>4488.0</td>\n",
       "      <td>8.500</td>\n",
       "      <td>8.437778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>1990</td>\n",
       "      <td>13431.0</td>\n",
       "      <td>8.455</td>\n",
       "      <td>8.434222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  year  vote_count  \\\n",
       "218                         The Shawshank Redemption  1994     28432.0   \n",
       "182                                    The Godfather  1972     21550.0   \n",
       "184                            The Godfather Part II  1974     13014.0   \n",
       "312                                 Schindler's List  1993     16468.0   \n",
       "87                                     Spirited Away  2001     17218.0   \n",
       "109                                  The Dark Knight  2008     33960.0   \n",
       "359                                   The Green Mile  1999     18150.0   \n",
       "519                                     Pulp Fiction  1994     28767.0   \n",
       "21756                                     Your Name.  2016     11814.0   \n",
       "82     The Lord of the Rings: The Return of the King  2003     25160.0   \n",
       "286                                     12 Angry Men  1957      9195.0   \n",
       "6                                       Forrest Gump  1994     28297.0   \n",
       "18073                                   Interstellar  2014     37303.0   \n",
       "7589                     Dilwale Dulhania Le Jayenge  1995      4488.0   \n",
       "575                                       GoodFellas  1990     13431.0   \n",
       "\n",
       "       vote_average        wr  \n",
       "218           8.711  8.700716  \n",
       "182           8.686  8.672497  \n",
       "184           8.571  8.549115  \n",
       "312           8.564  8.546712  \n",
       "87            8.537  8.520541  \n",
       "109           8.520  8.511668  \n",
       "359           8.505  8.489472  \n",
       "519           8.488  8.478222  \n",
       "21756         8.500  8.476200  \n",
       "82            8.486  8.474827  \n",
       "286           8.500  8.469458  \n",
       "6             8.468  8.458096  \n",
       "18073         8.455  8.447501  \n",
       "7589          8.500  8.437778  \n",
       "575           8.455  8.434222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell calculates the IMDb Weighted Rating (WR) and filters for a high-quality movie pool.\n",
    "\n",
    "# --- 1. Calculate Global Metrics (C and m) ---\n",
    "# We calculate these from the entire df_clean before aggressive filtering\n",
    "# to get stable, representative statistics.\n",
    "\n",
    "print(\"--- Calculating global metrics for Weighted Rating ---\")\n",
    "vote_averages = df_clean['vote_average']\n",
    "C = vote_averages.mean()\n",
    "print(f\"Global mean rating (C): {C:.4f}\")\n",
    "\n",
    "vote_counts = df_clean['vote_count']\n",
    "# Use the 95th percentile as our quality threshold 'm'\n",
    "m = vote_counts.quantile(0.95)\n",
    "print(f\"Global vote count threshold (m) at 95th percentile: {m:.1f}\")\n",
    "\n",
    "\n",
    "# --- 2. Filter DataFrame to get the \"Qualified\" Pool ---\n",
    "# A movie must have more votes than the threshold 'm' to be included.\n",
    "qualified_df = df_clean[df_clean['vote_count'] >= m].copy()\n",
    "print(f\"\\nNumber of 'qualified' movies passing the threshold: {len(qualified_df)}\")\n",
    "\n",
    "\n",
    "# --- 3. Calculate the Weighted Rating (WR) for Qualified Movies ---\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    \"\"\"Calculates the WR score based on the IMDb formula.\"\"\"\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    return (v / (v + m) * R) + (m / (m + v) * C)\n",
    "\n",
    "qualified_df['wr'] = qualified_df.apply(weighted_rating, axis=1)\n",
    "print(\"Weighted Rating (wr) calculated for all qualified movies.\")\n",
    "\n",
    "\n",
    "# --- 4. Final Cleanup of the Qualified Pool ---\n",
    "qualified_df.drop_duplicates(subset='title', keep='first', inplace=True)\n",
    "qualified_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Final number of unique, high-quality movies for our engine: {len(qualified_df)}\")\n",
    "\n",
    "\n",
    "# --- 5. Verify the Top Chart ---\n",
    "# The top movies list should now be populated with well-known classics.\n",
    "print(\"\\nTop 15 Movies based on the new Weighted Rating:\")\n",
    "display(qualified_df[['title', 'year', 'vote_count', 'vote_average', 'wr']].sort_values('wr', ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Part A: Building Content-Based Engine with BGE ---\n",
      "Using device: cuda\n",
      "\n",
      "Loading BGE model (BAAI/bge-base-en-v1.5)...\n",
      "\n",
      "Generating BGE embeddings from narrative text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a1663f4f474c418144f581ea7e0486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGE embeddings generated. Shape: (30269, 768)\n",
      "\n",
      "--- Part B: Building Collaborative Filtering Engine with SVD ---\n",
      "\n",
      "Training SVD on 96754 ratings from qualified movies.\n",
      "SVD model trained successfully.\n",
      "\n",
      "--- Part C: Saving all final artifacts ---\n",
      "\n",
      "--- SUCCESS! All final, high-quality artifacts are generated and ready. ---\n"
     ]
    }
   ],
   "source": [
    "# This final cell generates and saves all artifacts required for the hybrid recommender.\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from surprise import SVD, Reader, Dataset\n",
    "from pathlib import Path\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# --- Part A: BGE Content Engine Artifacts ---\n",
    "print(\"--- Part A: Building Content-Based Engine with BGE ---\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load BGE Model\n",
    "print(\"\\nLoading BGE model (BAAI/bge-base-en-v1.5)...\")\n",
    "bge_model = SentenceTransformer('BAAI/bge-base-en-v1.5', device=device)\n",
    "\n",
    "# Generate BGE Embeddings from the narrative text of our qualified movies\n",
    "print(\"\\nGenerating BGE embeddings from narrative text...\")\n",
    "sentences = qualified_df['narrative_text'].tolist()\n",
    "bge_embeddings = bge_model.encode(sentences, show_progress_bar=True, device=device)\n",
    "print(f\"BGE embeddings generated. Shape: {bge_embeddings.shape}\")\n",
    "\n",
    "\n",
    "# --- Part B: SVD Collaborative Filtering Engine Artifacts ---\n",
    "print(\"\\n--- Part B: Building Collaborative Filtering Engine with SVD ---\")\n",
    "# 1. Load MovieLens data\n",
    "ratings_path = '../data/ml-latest-small/ratings.csv'\n",
    "links_path = '../data/ml-latest-small/links.csv'\n",
    "ratings_df = pd.read_csv(ratings_path)\n",
    "links_df = pd.read_csv(links_path)\n",
    "\n",
    "# 2. Prepare data for Surprise\n",
    "# Map MovieLens' movieId to TMDB's id\n",
    "links_df.rename(columns={'tmdbId': 'id'}, inplace=True)\n",
    "ratings_with_tmdb_id = pd.merge(ratings_df, links_df[['movieId', 'id']], on='movieId', how='left')\n",
    "ratings_with_tmdb_id.dropna(subset=['id'], inplace=True)\n",
    "ratings_with_tmdb_id['id'] = ratings_with_tmdb_id['id'].astype(int)\n",
    "\n",
    "# 3. Filter ratings to ONLY include movies that are in our final qualified_df\n",
    "ratings_filtered = ratings_with_tmdb_id[ratings_with_tmdb_id['id'].isin(qualified_df['id'])]\n",
    "print(f\"\\nTraining SVD on {len(ratings_filtered)} ratings from qualified movies.\")\n",
    "\n",
    "# 4. Train SVD model\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings_filtered[['userId', 'id', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "algo_svd = SVD(n_factors=100, n_epochs=20, random_state=42)\n",
    "algo_svd.fit(trainset)\n",
    "print(\"SVD model trained successfully.\")\n",
    "\n",
    "\n",
    "# --- Part C: Save All Synchronized Artifacts ---\n",
    "print(\"\\n--- Part C: Saving all final artifacts ---\")\n",
    "# The final DataFrame for our API is the qualified_df\n",
    "final_api_df = qualified_df.copy()\n",
    "final_indices_map = pd.Series(final_api_df.index, index=final_api_df.title)\n",
    "\n",
    "SAVE_DIR = Path('../movie_recommender/saved_models/')\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "np.save(SAVE_DIR / 'bge_embeddings.npy', bge_embeddings)\n",
    "joblib.dump(final_api_df, SAVE_DIR / 'movies_df.joblib')\n",
    "joblib.dump(final_indices_map, SAVE_DIR / 'indices_map.joblib')\n",
    "joblib.dump(algo_svd, SAVE_DIR / 'svd_model.joblib')\n",
    "\n",
    "print(\"\\n--- SUCCESS! All final, high-quality artifacts are generated and ready. ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
